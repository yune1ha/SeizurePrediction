{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "f68d347a-d2a8-4427-a81a-eecee0c7f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import os, random, copy, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "bbc90cbe-339d-4808-b893-47d6042ed63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff18e789890>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "rcParams['figure.figsize'] = 14, 10\n",
    "register_matplotlib_converters()\n",
    "RANDOM_SEED = 369\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "cfca8041-b06e-47fa-89ff-0428f5ee178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "arr_dir = '/home/SharedFiles/Projects/EEG/Data/seg_arr/seq05m_seg30s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "3fb6ee96-9657-4b4f-b52a-a258a69c57c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_preictals of n patients; n = 11\n",
      "all_interictals of n patients; n = 11\n"
     ]
    }
   ],
   "source": [
    "# retrieve all paths\n",
    "all_preictals, all_interictals, patients = [], [], []\n",
    "for patient in os.listdir(arr_dir):\n",
    "    if patient.startswith('SNUCH'):\n",
    "        patient_pth = os.path.join(arr_dir, patient)\n",
    "        patients.append(patient)\n",
    "        all_preictals.append([])\n",
    "        all_interictals.append([])\n",
    "        for ictalType in os.listdir(patient_pth):\n",
    "            ictalType_pth = os.path.join(patient_pth, ictalType) \n",
    "            if os.path.isdir(ictalType_pth):\n",
    "                if ictalType == 'preictals':\n",
    "                    for preictal in os.listdir(ictalType_pth):\n",
    "                        if not preictal.startswith('._'):\n",
    "                            preictal_pth = os.path.join(ictalType_pth, preictal)\n",
    "                            all_preictals[-1].append(preictal_pth)\n",
    "                if ictalType == 'interictals':\n",
    "                    for interictal in os.listdir(ictalType_pth):\n",
    "                        if not interictal.startswith('._'):\n",
    "                            interictal_pth = os.path.join(ictalType_pth, interictal)\n",
    "                            all_interictals[-1].append(interictal_pth)\n",
    "\n",
    "                            \n",
    "print('all_preictals of n patients; n =', len(all_preictals))\n",
    "print('all_interictals of n patients; n =', len(all_interictals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4d37a5d2-41cf-4455-80e5-604c89250474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_preictals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee8555-401d-4208-ae96-65d3a322f6f6",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3948adf3-cf1b-4a34-bd46-2a5f08256e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train valid test split\n",
    "def split_data(preictals, interictals, train_ratio):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "    random.shuffle(preictals)\n",
    "    random.shuffle(interictals)\n",
    "    \n",
    "    preictals_train_size = int(len(preictals)*train_ratio)\n",
    "    preictals_val_size = int((len(preictals)-preictals_train_size)/2)\n",
    "    preictals_val_ind = preictals_train_size + preictals_val_size - 1\n",
    "    X_train += [np.load(array) for array in preictals[:preictals_train_size]]\n",
    "    X_val += [np.load(array) for array in preictals[preictals_train_size:preictals_val_ind]]\n",
    "    X_test += [np.load(array) for array in preictals[preictals_val_ind:]]\n",
    "    y_train += [1 for ictal in range(preictals_train_size)]\n",
    "    y_val += [1 for ictal in range(preictals_val_size)]\n",
    "    y_test += [1 for ictal in range(len(preictals[preictals_val_ind:]))]\n",
    "\n",
    "    interictals_train_size = int(len(interictals)*train_ratio)\n",
    "    interictals_val_size = int((len(interictals)-interictals_train_size)/2)\n",
    "    interictals_val_ind = interictals_train_size + interictals_val_size - 1\n",
    "    X_train += [np.load(array) for array in interictals[:interictals_train_size]]\n",
    "    X_val += [np.load(array) for array in interictals[interictals_train_size:interictals_val_ind]]\n",
    "    X_test += [np.load(array) for array in interictals[interictals_val_ind:]]\n",
    "    y_train += [0 for ictal in range(interictals_train_size)]\n",
    "    y_val += [0 for ictal in range(interictals_val_size)]\n",
    "    y_test += [0 for ictal in range(len(interictals[interictals_val_ind:]))]\n",
    "    \n",
    "    return np.array(X_train), np.array(y_train), np.array(X_val), np.array(y_val), np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "95562318-c4d6-4542-89e5-85c4c6f4bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(all_preictals[0], all_interictals[0], 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "a92e4cc1-5320-4885-bd54-8e3e2c2778b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train) + len(X_val) + len(X_test) == len(y_train) + len(y_val) + len(y_test) == len(all_preictals[0]) + len(all_interictals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "ac8a9053-b0e6-4590-b5f3-76ab14370db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale\n",
    "\n",
    "MIN = X_train.min()\n",
    "MAX = X_train.max()\n",
    "\n",
    "def MinMaxScale(array, min, max):\n",
    "    return (array - min) / (max - min)\n",
    "\n",
    "#MinMax 스케일링\n",
    "X_train = MinMaxScale(X_train, MIN, MAX)\n",
    "X_val = MinMaxScale(X_val, MIN, MAX)\n",
    "X_test = MinMaxScale(X_test, MIN, MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "2757cb3e-adc5-428a-a40a-3d68bc515012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler() # 2D only\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.fit_transform(X_val)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "eacd5291-0f9e-47e4-a371-570a321e47c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([754, 21, 6000]) torch.Size([162, 21, 6000]) torch.Size([162, 21, 6000])\n",
      "torch.Size([754]) torch.Size([162]) torch.Size([162])\n"
     ]
    }
   ],
   "source": [
    "def make_Tensor(array):\n",
    "    return torch.from_numpy(array).float()\n",
    "\n",
    "X_train = make_Tensor(X_train)\n",
    "y_train = make_Tensor(y_train)\n",
    "X_val = make_Tensor(X_val)\n",
    "y_val = make_Tensor(y_val)\n",
    "X_test = make_Tensor(X_test)\n",
    "y_test = make_Tensor(y_test)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590b947-6b24-4be2-9672-19d3d2e98775",
   "metadata": {},
   "source": [
    "# Model (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b05e0-9408-4494-a312-cfa3d910a357",
   "metadata": {},
   "source": [
    "https://pseudo-lab.github.io/Tutorial-Book/chapters/time-series/Ch4-LSTM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "79c94c99-568b-404a-8048-45c1db3ccedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeizurePredictorLSTM(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden, seg_len, n_layers):\n",
    "        #print('n_features', n_features) ## TEST\n",
    "        #print('seg_len', seg_len) ## TEST\n",
    "        super(SeizurePredictorLSTM, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.seg_len = seg_len\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=n_hidden,\n",
    "            num_layers=n_layers\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=n_hidden, out_features=2)\n",
    "    def reset_hidden_state(self):\n",
    "        self.hidden = (\n",
    "            torch.zeros(self.n_layers, self.seg_len, self.n_hidden),\n",
    "            torch.zeros(self.n_layers, self.seg_len, self.n_hidden)\n",
    "        )\n",
    "    def forward(self, sequences):\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            sequences.view(len(sequences), self.seg_len, -1),\n",
    "            self.hidden\n",
    "        )\n",
    "        last_time_step = lstm_out.view(self.seg_len, len(sequences), self.n_hidden)[-1]\n",
    "        y_pred = self.linear(last_time_step)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c9ccc-30e4-4e4a-a334-ef5825c8e07c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "bb61814d-eb42-46b9-9c9d-9aee3cda5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST\n",
    "# model = SeizurePredictorLSTM(\n",
    "#     n_features=len(X_train[0]),\n",
    "#     n_hidden=4,\n",
    "#     n_layers=1,\n",
    "#     seg_len = len(X_train[0][0])\n",
    "# )\n",
    "# model=model\n",
    "# train_data = X_train\n",
    "# train_labels = y_train\n",
    "# val_data = X_val\n",
    "# val_labels = y_val\n",
    "# num_epochs=2\n",
    "# verbose=1\n",
    "# patience=50\n",
    "\n",
    "def train_model(model, train_data, train_labels, val_data, val_labels, num_epochs, verbose, patience):\n",
    "\n",
    "    loss_fn = torch.nn.L1Loss() #\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "    val_auc = []\n",
    "    for t in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for idx, ictal in enumerate(train_data): \n",
    "            model.reset_hidden_state() # ictal 별 hidden state reset\n",
    "\n",
    "            # train loss\n",
    "            ictal = torch.unsqueeze(ictal, 0)\n",
    "            y_pred = model(ictal)\n",
    "            loss = loss_fn(y_pred[0].float(), train_labels[idx].view(-1,1,1)) # 1개의 step에 대한 loss\n",
    "\n",
    "            # update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        train_hist.append(epoch_loss / len(train_data))\n",
    "\n",
    "        if val_data is not None:\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                val_preds = []\n",
    "                for val_idx, val_ictal in enumerate(val_data):\n",
    "                    model.reset_hidden_state() # ictal 별로 hidden state 초기화 \n",
    "\n",
    "                    val_ictal = torch.unsqueeze(val_ictal, 0)\n",
    "                    y_val_pred = model(val_ictal)\n",
    "                    val_preds.append(y_val_pred[0].float())\n",
    "                    val_step_loss = loss_fn(y_val_pred[0].float(), val_labels[val_idx].view(-1,1,1))\n",
    "\n",
    "                    val_loss += val_step_loss\n",
    "                    \n",
    "                    \n",
    "\n",
    "            val_hist.append(val_loss / len(val_data)) # val hist에 추가\n",
    "\n",
    "            ## verbose 번째 마다 loss 출력 \n",
    "            if t % verbose == 0:\n",
    "                print(f'Epoch {t} train loss: {epoch_loss / len(train_data)} val loss: {val_loss / len(val_data)}')\n",
    "\n",
    "                # print('val_labels shape', val_labels.cpu().detach().numpy().shape)\n",
    "                # print('val_labels[0]', val_labels.cpu().detach().numpy()[0])\n",
    "                # print('val_preds shape', np.array(val_preds).shape)\n",
    "                # print('val_preds[0]', np.array(val_preds)[0])\n",
    "                auc = roc_auc_score(val_labels.cpu().detach().numpy(), val_preds)#.cpu().detach().numpy())\n",
    "                val_auc.append(auc)\n",
    "\n",
    "                print(\"Validation AUC: {}\".format(auc))\n",
    "            ## patience 번째 마다 early stopping 여부 확인\n",
    "            if (t % patience == 0) & (t != 0):\n",
    "                ## loss가 커졌다면 early stop\n",
    "                if val_hist[t - patience] < val_hist[t] :\n",
    "                    print('\\n Early Stopping')\n",
    "                    break\n",
    "\n",
    "        elif t % verbose == 0:\n",
    "            print(f'Epoch {t} train loss: {epoch_loss / len(train_data)}')\n",
    "\n",
    "\n",
    "    return model, train_hist, val_hist, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "cb36c707-2f37-4b09-b93a-b62111866456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "767d0166-dcf8-4c89-8fa5-45f3c40a216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_labels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "37858acf-be71-491a-b230-cd341adafc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/eeg/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([1, 1, 1])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.2654950601994912 val loss: 0.49999791383743286\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26858/2606892475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseg_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m model, train_hist, val_hist, val_auc= train_model(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26858/386050690.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, train_labels, val_data, val_labels, num_epochs, verbose, patience)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;31m# print('val_preds shape', np.array(val_preds).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;31m# print('val_preds[0]', np.array(val_preds)[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.cpu().detach().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mval_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eeg/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eeg/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     if y_type == \"multiclass\" or (y_type == \"binary\" and\n",
      "\u001b[0;32m/opt/anaconda3/envs/eeg/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eeg/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/envs/eeg/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "model = SeizurePredictorLSTM(\n",
    "    n_features=len(X_train[0]),\n",
    "    n_hidden=4,\n",
    "    n_layers=1,\n",
    "    seg_len = len(X_train[0][0])\n",
    ")\n",
    "model, train_hist, val_hist, val_auc= train_model(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    num_epochs=100,\n",
    "    verbose=1,\n",
    "    patience=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b51f9-ff91-4c10-b450-dc8ec6f2f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.plot(val_hist, label=\"Val loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0cd41-039f-4e69-bc3c-16b362299242",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417b2cf-729f-481e-81ee-388ebb810588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eeg]",
   "language": "python",
   "name": "conda-env-eeg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
